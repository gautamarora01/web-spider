# Web Spider Project
A command-line application that takes in a web URL, depth of recursion as input and downloads its contents locally into 
a file, till the depth specified, recursively trying out all links.

Execute using spider-cli.js
To run code:
```bash
git clone
npm install
node ./spider-cli URL_TO_PARSE RECURSIVE_DEPTH
```
